@article{Lin_Wang_Xu_Liu_2025, title={Semi-IIN: Semi-Supervised Intra-Inter Modal Interaction Learning Network for Multimodal Sentiment Analysis}, volume={39}, url={https://ojs.aaai.org/index.php/AAAI/article/view/32131}, DOI={10.1609/aaai.v39i2.32131}, abstractNote={Despite multimodal sentiment analysis being a fertile research ground that merits further investigation, current approaches take up high annotation cost and suffer from label ambiguity, non-amicable to high-quality labeled data acquisition. Furthermore, choosing the right interactions is essential because the significance of intra- or inter-modal interactions can differ among various samples. To this end, we propose Semi-IIN, a Semi-supervised Intra-inter modal Interaction learning Network for multimodal sentiment analysis. Semi-IIN integrates masked attention and gating mechanisms, enabling effective dynamic selection after independently capturing intra- and inter-modal interactive information. Combined with the self-training approach, Semi-IIN fully utilizes the knowledge learned from unlabeled data. Experimental results on two public datasets, MOSI and MOSEI, demonstrate the effectiveness of Semi-IIN, establishing a new state-of-the-art on several metrics.}, number={2}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Lin, Jinhao and Wang, Yifei and Xu, Yanwu and Liu, Qi}, year={2025}, month={Apr.}, pages={1411-1419} }
