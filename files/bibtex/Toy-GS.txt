@article{Zhang_Sun_Qiu_Su_Liu_2025, title={Toy-GS: Assembling Local Gaussians for Precisely Rendering Large-Scale Free Camera Trajectories}, volume={39}, url={https://ojs.aaai.org/index.php/AAAI/article/view/33108}, DOI={10.1609/aaai.v39i10.33108}, abstractNote={Currently, 3D rendering for large-scale free camera trajectories, namely, arbitrary input camera trajectories, poses significant challenges: 1) The distribution and observation angles of the cameras are irregular, and various types of scenes are included in the free trajectories; 2) Processing the entire point cloud and all images at once for large-scale scenes requires a substantial amount of GPU memory. This paper presents a Toy-GS method for accurately rendering large-scale free camera trajectories. Specifically, we propose an adaptive spatial division approach for free trajectories to divide cameras and the sparse point cloud of the entire scene into various regions according to camera poses. Training each local Gaussian in parallel for each area enables us to concentrate on texture details and minimize GPU memory usage. Next, we use the multi-view constraint and position-aware point adaptive control (PPAC) to improve the rendering quality of texture details. In addition, our regional fusion approach combines local and global Gaussians to enhance rendering quality with an increasing number of divided areas. Extensive experiments have been carried out to confirm the effectiveness and efficiency of Toy-GS, leading to state-of-the-art results on two public large-scale datasets as well as our SCUTic dataset. Our proposal demonstrates an enhancement of 1.19 dB in PSNR and conserves 7 G of GPU memory when compared to various benchmarks.}, number={10}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Zhang, Xiaohan and Sun, Zhenyu and Qiu, Yukui and Su, Junyan and Liu, Qi}, year={2025}, month={Apr.}, pages={10212-10220} }
